#!/usr/bin/env python3
"""
Version Tracking System

Adds metadata headers to all generated files, tracking source books,
models used, and regeneration commands.

Author: NBA MCP Synthesis System
Version: 3.0
"""

import hashlib
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)


class VersionTracker:
    """Track versions and metadata for generated files."""

    VERSION = "3.0"
    SYSTEM_NAME = "NBA MCP Synthesis System"

    def __init__(self, config_path: Optional[Path] = None):
        """
        Initialize Version Tracker.

        Args:
            config_path: Optional path to configuration file
        """
        self.config_path = config_path
        logger.info("Version Tracker initialized")

    def generate_file_header(
        self,
        generator_script: str,
        source_books: List[Dict],
        models_used: Dict,
        config_version: str = "2.0",
        regenerate_command: Optional[str] = None,
        additional_metadata: Optional[Dict] = None
    ) -> str:
        """
        Generate version header for file.

        Args:
            generator_script: Name of script that generated the file
            source_books: List of source book dicts with title and hash
            models_used: Dict of models used (e.g. {'gemini': 'version', 'claude': 'version'})
            config_version: Configuration file version
            regenerate_command: Command to regenerate the file
            additional_metadata: Additional metadata to include

        Returns:
            Header string
        """
        header = [
            '"""',
            f'Generated by: {self.SYSTEM_NAME} v{self.VERSION}',
            f'Generated at: {datetime.now().isoformat()}',
            f'Generator: {generator_script}',
            ''
        ]

        # Source books
        if source_books:
            header.append('Source Books:')
            for book in source_books:
                title = book.get('title', 'Unknown')
                content_hash = book.get('hash', book.get('content_hash', 'N/A'))
                if len(content_hash) > 8:
                    content_hash = content_hash[:8]
                header.append(f'- {title} (hash: {content_hash})')
            header.append('')

        # Models used
        if models_used:
            header.append('Models Used:')
            for model, version in models_used.items():
                header.append(f'- {model.capitalize()}: {version}')
            header.append('')

        # Configuration
        header.append(f'Configuration: workflow_config.yaml v{config_version}')
        header.append('')

        # Regeneration command
        if regenerate_command:
            header.append(f'Regenerate: {regenerate_command}')
            header.append('')

        # Additional metadata
        if additional_metadata:
            header.append('Additional Metadata:')
            for key, value in additional_metadata.items():
                header.append(f'- {key}: {value}')
            header.append('')

        header.extend([
            'DO NOT EDIT THIS FILE MANUALLY',
            '"""',
            ''
        ])

        return '\n'.join(header)

    def generate_markdown_header(
        self,
        generator_script: str,
        source_books: List[Dict],
        models_used: Dict,
        regenerate_command: Optional[str] = None
    ) -> str:
        """
        Generate version header for Markdown file.

        Args:
            generator_script: Name of script that generated the file
            source_books: List of source book dicts
            models_used: Dict of models used
            regenerate_command: Command to regenerate

        Returns:
            Markdown header string
        """
        header = [
            '<!-- Version Metadata',
            f'Generated by: {self.SYSTEM_NAME} v{self.VERSION}',
            f'Generated at: {datetime.now().isoformat()}',
            f'Generator: {generator_script}'
        ]

        if source_books:
            header.append('Source Books:')
            for book in source_books:
                title = book.get('title', 'Unknown')
                content_hash = book.get('hash', book.get('content_hash', 'N/A'))[:8]
                header.append(f'  - {title} ({content_hash})')

        if models_used:
            header.append('Models: ' + ', '.join(
                f'{k}={v}' for k, v in models_used.items()
            ))

        if regenerate_command:
            header.append(f'Regenerate: {regenerate_command}')

        header.append('-->')
        header.append('')

        return '\n'.join(header)

    def add_header_to_file(
        self,
        file_path: Path,
        header: str,
        backup: bool = True
    ):
        """
        Add header to existing file.

        Args:
            file_path: Path to file
            header: Header to add
            backup: Whether to create backup
        """
        if not file_path.exists():
            logger.warning(f"File not found: {file_path}")
            return

        # Create backup if requested
        if backup:
            backup_path = file_path.with_suffix(file_path.suffix + '.bak')
            backup_path.write_text(file_path.read_text())
            logger.debug(f"Backup created: {backup_path}")

        # Read existing content
        content = file_path.read_text()

        # Check if header already exists
        if 'Generated by: NBA MCP Synthesis System' in content:
            logger.debug(f"Header already exists in {file_path}")
            return

        # Add header
        new_content = header + content
        file_path.write_text(new_content)
        logger.info(f"Header added to {file_path}")

    def get_book_hash(self, book_path: Path) -> str:
        """
        Get content hash for a book.

        Args:
            book_path: Path to book file

        Returns:
            SHA256 hash (first 8 chars)
        """
        if not book_path.exists():
            return 'N/A'

        try:
            content = book_path.read_text()
            hash_obj = hashlib.sha256(content.encode())
            return hash_obj.hexdigest()[:8]
        except Exception as e:
            logger.warning(f"Failed to hash {book_path}: {e}")
            return 'N/A'

    def get_source_books_metadata(
        self,
        books_dir: Path,
        book_names: List[str]
    ) -> List[Dict]:
        """
        Get metadata for source books.

        Args:
            books_dir: Directory containing books
            book_names: List of book names

        Returns:
            List of book metadata dicts
        """
        metadata = []

        for book_name in book_names:
            # Try to find the book file
            book_files = list(books_dir.glob(f'{book_name}*'))

            if book_files:
                book_path = book_files[0]
                book_hash = self.get_book_hash(book_path)
                metadata.append({
                    'title': book_name,
                    'hash': book_hash,
                    'path': str(book_path)
                })
            else:
                metadata.append({
                    'title': book_name,
                    'hash': 'N/A',
                    'path': 'Not found'
                })

        return metadata

    def create_version_manifest(
        self,
        output_dir: Path,
        files: List[Path],
        metadata: Dict
    ):
        """
        Create version manifest for a set of generated files.

        Args:
            output_dir: Directory containing generated files
            files: List of generated file paths
            metadata: Metadata about the generation process
        """
        manifest = {
            'system': self.SYSTEM_NAME,
            'version': self.VERSION,
            'generated_at': datetime.now().isoformat(),
            'output_directory': str(output_dir),
            'total_files': len(files),
            'files': [],
            'metadata': metadata
        }

        # Add file information
        for file_path in files:
            if file_path.exists():
                stat = file_path.stat()
                manifest['files'].append({
                    'path': str(file_path.relative_to(output_dir)),
                    'size_bytes': stat.st_size,
                    'created': datetime.fromtimestamp(stat.st_ctime).isoformat()
                })

        # Save manifest
        manifest_path = output_dir / 'VERSION_MANIFEST.json'
        with open(manifest_path, 'w') as f:
            json.dump(manifest, f, indent=2)

        logger.info(f"Version manifest created: {manifest_path}")

    def add_headers_to_directory(
        self,
        directory: Path,
        generator_script: str,
        source_books: List[Dict],
        models_used: Dict,
        regenerate_command: Optional[str] = None,
        file_pattern: str = '*.py',
        backup: bool = True
    ):
        """
        Add headers to all files in a directory.

        Args:
            directory: Directory to process
            generator_script: Name of generator script
            source_books: Source books metadata
            models_used: Models used
            regenerate_command: Regeneration command
            file_pattern: File pattern to match
            backup: Whether to create backups
        """
        if not directory.exists():
            logger.error(f"Directory not found: {directory}")
            return

        files = list(directory.glob(file_pattern))
        logger.info(f"Adding headers to {len(files)} files in {directory}")

        # Generate header
        if file_pattern.endswith('.py'):
            header = self.generate_file_header(
                generator_script=generator_script,
                source_books=source_books,
                models_used=models_used,
                regenerate_command=regenerate_command
            )
        elif file_pattern.endswith('.md'):
            header = self.generate_markdown_header(
                generator_script=generator_script,
                source_books=source_books,
                models_used=models_used,
                regenerate_command=regenerate_command
            )
        else:
            logger.warning(f"Unsupported file pattern: {file_pattern}")
            return

        # Add header to each file
        for file_path in files:
            try:
                self.add_header_to_file(file_path, header, backup=backup)
            except Exception as e:
                logger.error(f"Failed to add header to {file_path}: {e}")

        logger.info(f"Headers added to {len(files)} files")


def main():
    """Test version tracking."""
    import argparse

    parser = argparse.ArgumentParser(description='Version Tracker')
    parser.add_argument('--directory', type=Path, help='Directory to add headers to')
    parser.add_argument('--pattern', default='*.py', help='File pattern (default: *.py)')
    parser.add_argument('--generator', default='unknown', help='Generator script name')
    parser.add_argument('--no-backup', action='store_true', help='Skip backups')
    args = parser.parse_args()

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    tracker = VersionTracker()

    if args.directory:
        # Example metadata
        source_books = [
            {'title': 'Example Book 1', 'hash': 'a1b2c3d4'},
            {'title': 'Example Book 2', 'hash': 'e5f6g7h8'}
        ]
        models_used = {
            'gemini': 'gemini-2.0-flash-exp',
            'claude': 'claude-sonnet-4'
        }
        regenerate_command = 'python scripts/run_full_workflow.py --book "All Books"'

        tracker.add_headers_to_directory(
            directory=args.directory,
            generator_script=args.generator,
            source_books=source_books,
            models_used=models_used,
            regenerate_command=regenerate_command,
            file_pattern=args.pattern,
            backup=not args.no_backup
        )

        print(f"\nâœ… Headers added to files in {args.directory}")
    else:
        # Print example header
        source_books = [
            {'title': 'Designing Machine Learning Systems', 'hash': 'a3f8e2c1'},
            {'title': 'Practical MLOps', 'hash': 'b7d9f4a2'}
        ]
        models_used = {
            'gemini': 'gemini-2.0-flash-exp',
            'claude': 'claude-sonnet-4'
        }
        regenerate_command = 'python scripts/run_full_workflow.py --book "All Books" --parallel'

        header = tracker.generate_file_header(
            generator_script='phase4_file_generation.py',
            source_books=source_books,
            models_used=models_used,
            regenerate_command=regenerate_command
        )

        print("\n" + "="*60)
        print("Example Python File Header:")
        print("="*60)
        print(header)

        md_header = tracker.generate_markdown_header(
            generator_script='phase4_file_generation.py',
            source_books=source_books,
            models_used=models_used,
            regenerate_command=regenerate_command
        )

        print("\n" + "="*60)
        print("Example Markdown File Header:")
        print("="*60)
        print(md_header)


if __name__ == '__main__':
    main()





