# Phase 1 Week 4 - Documentation & Quality Roadmap

**Goal:** Complete Documentation, Fix Test Failures, Performance Optimization
**Estimated Total Time:** 12-16 hours across 3 sub-phases
**Status:** Ready to Begin

---

## üéØ Overview

Phase 1 Week 3 successfully completed production hardening with exception integration across all 5 core analytical modules (41 custom exception replacements). Week 4 focuses on:

1. **Bug Fixes** - Resolve 12 failing tests from exception integration
2. **Documentation** - Create comprehensive user guides and API reference
3. **Quality** - Build integration test suite and optimize performance

**Current State:**
- ‚úÖ 26+ econometric methods implemented
- ‚úÖ 167/179 tests passing (93.3% pass rate)
- ‚úÖ Exception handling integrated across all modules
- ‚úÖ 10 example notebooks created
- ‚è≥ 12 failing tests need fixes
- ‚è≥ Documentation needs expansion
- ‚è≥ Integration testing needed

---

## üîß **Sub-Phase A: Test Fixes & Stabilization (3-4 hours)**

### **1. Fix Exception Integration Test Failures (2 hours)**

**Current Failures:** 12 tests failing in:
- `test_econometric_suite.py` (1 test)
- `test_causal_inference.py` (5 tests)
- `test_panel_data.py` (1 test)
- `test_survival_analysis.py` (5 tests)

**Root Cause:** Tests expect old exception types (ValueError, KeyError) but modules now raise custom exceptions (InvalidParameterError, MissingParameterError, etc.)

**Actions:**

**Step 1: Update Test Expectations** (1 hour)
```python
# Before (fails now):
with pytest.raises(ValueError):
    analyzer.method(bad_params)

# After (correct):
from mcp_server.exceptions import InvalidParameterError
with pytest.raises(InvalidParameterError):
    analyzer.method(bad_params)
```

**Files to Update:**
- `tests/test_causal_inference.py:228` - Update PSM test expectations
- `tests/test_causal_inference.py:245` - Update common support test
- `tests/test_causal_inference.py:260` - Update no covariates test
- `tests/test_causal_inference.py:350` - Update sensitivity test
- `tests/test_causal_inference.py:450` - Update analyzer validation
- `tests/test_panel_data.py:180` - Update invalid column test
- `tests/test_survival_analysis.py:320` - Update time-varying tests
- `tests/test_survival_analysis.py:400` - Update validation tests
- `tests/test_econometric_suite.py:550` - Update competing risks test

**Step 2: Run Tests & Verify** (30 min)
```bash
# Run failing tests
pytest tests/test_causal_inference.py tests/test_panel_data.py tests/test_survival_analysis.py -v

# Expected: All tests passing
# Target: 179/179 tests passing (100% pass rate)
```

**Step 3: Fix Any NumPy/Statsmodels Issues** (30 min)
```python
# Handle numerical errors gracefully
try:
    result = np.linalg.solve(X, y)
except np.linalg.LinAlgError as e:
    raise NumericalError("Matrix inversion failed - check for collinearity") from e
```

**Deliverables:**
- ‚úÖ All 179 tests passing
- ‚úÖ 100% test pass rate
- ‚úÖ No exception handling regressions

### **2. Add Missing Test Coverage (1 hour)**

**Goal:** Achieve >95% code coverage on all modules

**Actions:**

**Coverage Analysis:**
```bash
pytest tests/ --cov=mcp_server --cov-report=html --cov-report=term-missing
open htmlcov/index.html
```

**Add Edge Case Tests:**
```python
# tests/test_edge_cases.py
def test_arima_with_insufficient_data():
    """Test ARIMA with <30 observations raises InsufficientDataError"""
    data = pd.Series(np.random.randn(20))
    suite = EconometricSuite(data=data, target='value')
    with pytest.raises(InsufficientDataError):
        suite.time_series_analysis(method='arima')

def test_panel_with_single_entity():
    """Test panel data with only 1 entity"""
    data = pd.DataFrame({
        'entity': [1]*10,
        'time': range(10),
        'y': np.random.randn(10)
    })
    with pytest.raises(InsufficientDataError):
        analyzer = PanelDataAnalyzer(data=data, entity_col='entity', time_col='time')
```

**Deliverables:**
- ‚úÖ >95% code coverage on all modules
- ‚úÖ Edge case tests for all major methods
- ‚úÖ Coverage report generated

### **3. Performance Benchmarking** (1 hour)**

**Goal:** Establish performance baselines for all 26 methods

**Create Benchmark Script:**
```python
# scripts/benchmark_all_methods.py
import time
import pandas as pd
import numpy as np
from mcp_server.econometric_suite import EconometricSuite

DATASET_SIZES = [100, 1000, 10000, 100000]
METHODS = ['arima', 'var', 'kalman', 'panel_fe', 'panel_re', 'psm', 'rdd', 'iv', 'cox', 'kaplan_meier']

def benchmark_method(method, size):
    """Benchmark a single method at specific data size"""
    data = generate_data(method, size)
    suite = EconometricSuite(data=data, **method_kwargs(method))

    start = time.time()
    result = suite.analyze(method=method)
    elapsed = time.time() - start

    return {
        'method': method,
        'size': size,
        'time_seconds': elapsed,
        'rows_per_second': size / elapsed
    }

# Run benchmarks
results = []
for method in METHODS:
    for size in DATASET_SIZES:
        results.append(benchmark_method(method, size))

# Save results
df = pd.DataFrame(results)
df.to_csv('benchmark_results.csv', index=False)
```

**Run Benchmarks:**
```bash
python scripts/benchmark_all_methods.py
# Expected time: 10-15 minutes
```

**Deliverables:**
- ‚úÖ Performance baselines for all 26 methods
- ‚úÖ Benchmark results CSV file
- ‚úÖ Performance documentation in docs/PERFORMANCE.md

---

## üìö **Sub-Phase B: Comprehensive Documentation (5-7 hours)**

### **1. Quick Start Guide (2 hours)**

**File:** `docs/QUICK_START.md`

**Structure:**
```markdown
# Quick Start Guide

## Installation
```bash
pip install -e .
```

## 5-Minute Tutorial

### 1. Time Series Analysis (ARIMA)
```python
from mcp_server.econometric_suite import EconometricSuite
import pandas as pd

# Load your data
data = pd.DataFrame({
    'date': pd.date_range('2020-01-01', periods=100),
    'points': np.random.randn(100).cumsum() + 20
})

# Create suite
suite = EconometricSuite(
    data=data,
    target='points',
    time_col='date'
)

# Run ARIMA auto-detection
result = suite.time_series_analysis(method='arima', order='auto')
print(f"AIC: {result.result.aic:.2f}")

# Forecast 10 steps
forecast = result.result.forecast(steps=10)
print(forecast)
```

### 2. Causal Inference (Propensity Score Matching)
```python
# Load treatment data
data = pd.DataFrame({
    'player_id': range(100),
    'treatment': np.random.binomial(1, 0.5, 100),  # new training program
    'experience': np.random.uniform(0, 10, 100),
    'position': np.random.choice(['PG', 'SG', 'SF', 'PF', 'C'], 100),
    'outcome': np.random.randn(100) + 5
})

# Run PSM
suite = EconometricSuite(
    data=data,
    target='outcome',
    treatment_col='treatment'
)

result = suite.causal_analysis(
    method='psm',
    covariates=['experience', 'position'],
    caliper=0.1
)

print(f"ATT: {result.result.att:.3f}")
print(f"p-value: {result.result.p_value:.3f}")
```

### 3. Survival Analysis (Career Longevity)
```python
# Load career data
data = pd.DataFrame({
    'player_id': range(100),
    'career_length': np.random.exponential(5, 100),  # years
    'retired': np.random.binomial(1, 0.7, 100),  # 1=retired, 0=active
    'draft_pick': np.random.uniform(1, 60, 100),
    'injuries': np.random.poisson(2, 100)
})

# Run Cox PH
suite = EconometricSuite(
    data=data,
    target='career_length',
    duration_col='career_length',
    event_col='retired'
)

result = suite.survival_analysis(
    method='cox',
    covariates=['draft_pick', 'injuries']
)

# Interpret hazard ratios
print(result.result.summary())
```

## Common Workflows

### Player Performance Forecasting
1. Load historical player stats
2. Check stationarity (ADF test)
3. Fit ARIMA model
4. Generate forecasts
5. Evaluate forecast accuracy

### Team Strategy Optimization
1. Define treatment (e.g., lineup change)
2. Identify confounding variables
3. Run PSM or IV estimation
4. Estimate treatment effect
5. Check sensitivity to unobserved confounding

### Career Arc Modeling
1. Load player career data
2. Define duration and event variables
3. Fit survival model (Cox PH or parametric)
4. Interpret hazard ratios
5. Predict survival curves

## Error Handling

### Custom Exceptions
```python
from mcp_server.exceptions import (
    InsufficientDataError,
    InvalidParameterError,
    ModelFitError
)

try:
    result = suite.time_series_analysis(method='arima', order=(1,1,1))
except InsufficientDataError as e:
    print(f"Need more data: {e.details['min_required']} rows required")
except ModelFitError as e:
    print(f"Model failed to converge: {e.reason}")
```

## Next Steps

- See `examples/` for complete notebooks
- Read API documentation: `docs/API_REFERENCE.md`
- Check best practices: `docs/BEST_PRACTICES.md`
- Troubleshoot: `docs/TROUBLESHOOTING.md`
```

**Deliverables:**
- ‚úÖ Complete quick start guide with working examples
- ‚úÖ 5-minute tutorial for each major method category
- ‚úÖ Common workflows documented

### **2. API Reference Documentation (3 hours)**

**File:** `docs/API_REFERENCE.md`

**Structure:**
```markdown
# API Reference

Complete reference for all 26 econometric methods in the NBA MCP Analytics Platform.

## Table of Contents

1. [EconometricSuite](#econometricsuite)
2. [Time Series Analysis](#time-series-analysis)
3. [Panel Data Analysis](#panel-data-analysis)
4. [Bayesian Methods](#bayesian-methods)
5. [Causal Inference](#causal-inference)
6. [Survival Analysis](#survival-analysis)
7. [Advanced Time Series](#advanced-time-series)
8. [Custom Exceptions](#custom-exceptions)

---

## EconometricSuite

Main interface for all econometric analyses.

### `__init__(data, target, **kwargs)`

Initialize suite with data and configuration.

**Parameters:**
- `data` (pd.DataFrame): Input dataset
- `target` (str): Target variable name
- `time_col` (str, optional): Time column for time series
- `entity_col` (str, optional): Entity column for panel data
- `duration_col` (str, optional): Duration column for survival
- `event_col` (str, optional): Event column for survival
- `treatment_col` (str, optional): Treatment column for causal inference

**Raises:**
- `InvalidDataError`: If data is not a DataFrame
- `InvalidParameterError`: If required columns missing
- `InsufficientDataError`: If data has <30 rows

**Example:**
```python
suite = EconometricSuite(
    data=df,
    target='points',
    time_col='date'
)
```

### `analyze(method='auto', **kwargs)`

Run analysis with specified or auto-detected method.

**Parameters:**
- `method` (str): Method name or 'auto'
- `**kwargs`: Method-specific parameters

**Returns:**
- `SuiteResult`: Result object with:
  - `result`: Method-specific result object
  - `aic`: Akaike Information Criterion (if applicable)
  - `bic`: Bayesian Information Criterion (if applicable)
  - `diagnostics`: Diagnostic statistics

**Raises:**
- `InvalidParameterError`: If method unknown
- `ModelFitError`: If model fails to converge

**Example:**
```python
result = suite.analyze(method='arima', order=(1,1,1))
print(f"AIC: {result.aic}")
```

### `compare_methods(methods, metric='aic')`

Compare multiple methods and select best.

**Parameters:**
- `methods` (list): List of method configurations
- `metric` (str): Comparison metric ('aic', 'bic', 'rmse')

**Returns:**
- `pd.DataFrame`: Comparison table with metrics

**Example:**
```python
methods = [
    {'category': 'time_series', 'method': 'arima', 'params': {'order': (1,1,1)}},
    {'category': 'time_series', 'method': 'var', 'params': {'maxlags': 2}}
]
comparison = suite.compare_methods(methods, metric='aic')
print(comparison)
```

---

## Time Series Analysis

Methods in `mcp_server.time_series.py`

### ARIMA

Autoregressive Integrated Moving Average model.

**Method:** `time_series_analysis(method='arima', **kwargs)`

**Parameters:**
- `order` (tuple or 'auto'): (p, d, q) order or 'auto' for auto-selection
- `seasonal` (bool): Include seasonal components
- `seasonal_order` (tuple): (P, D, Q, s) for seasonal ARIMA

**Returns:**
- `ARIMAResults`: Statsmodels ARIMA result object with:
  - `aic`, `bic`: Information criteria
  - `forecast(steps)`: Generate forecasts
  - `summary()`: Model summary
  - `plot_diagnostics()`: Diagnostic plots

**Example:**
```python
result = suite.time_series_analysis(method='arima', order=(1,1,1))
forecast = result.result.forecast(steps=10)
```

### VAR

Vector Autoregression for multivariate time series.

**Method:** `time_series_analysis(method='var', **kwargs)`

**Parameters:**
- `maxlags` (int or 'auto'): Maximum lags or auto-select with AIC
- `ic` (str): Information criterion for lag selection ('aic', 'bic')

**Returns:**
- `VARResults`: Statsmodels VAR result object

**Example:**
```python
result = suite.time_series_analysis(method='var', maxlags='auto', ic='aic')
```

[... Continue for all 26 methods ...]

---

## Custom Exceptions

All custom exceptions defined in `mcp_server/exceptions.py`

### InvalidDataError

Raised when input data is invalid or malformed.

**Attributes:**
- `message` (str): Error description
- `details` (dict): Additional context

**Example:**
```python
try:
    suite = EconometricSuite(data="not_a_dataframe", target='y')
except InvalidDataError as e:
    print(e.message)
    print(e.details)
```

[... Document all 15 exception types ...]
```

**Deliverables:**
- ‚úÖ Complete API reference for all 26 methods
- ‚úÖ Parameter descriptions with types
- ‚úÖ Return value documentation
- ‚úÖ Exception documentation
- ‚úÖ Working code examples for each method

### **3. Best Practices Guide (2 hours)**

**File:** `docs/BEST_PRACTICES.md`

**Structure:**
```markdown
# Best Practices for NBA MCP Analytics

## Method Selection

### Decision Tree

```
What data structure do you have?
‚îú‚îÄ Time series (observations over time)
‚îÇ  ‚îú‚îÄ Single variable ‚Üí ARIMA, Kalman Filter
‚îÇ  ‚îú‚îÄ Multiple variables ‚Üí VAR, Dynamic Factors
‚îÇ  ‚îî‚îÄ Regime changes ‚Üí Markov Switching
‚îú‚îÄ Panel data (entities √ó time)
‚îÇ  ‚îú‚îÄ Fixed effects ‚Üí panel_fe
‚îÇ  ‚îú‚îÄ Random effects ‚Üí panel_re
‚îÇ  ‚îî‚îÄ Choose with Hausman test
‚îú‚îÄ Treatment effect question
‚îÇ  ‚îú‚îÄ Discontinuity ‚Üí RDD
‚îÇ  ‚îú‚îÄ Instrument available ‚Üí IV/2SLS
‚îÇ  ‚îî‚îÄ Matching ‚Üí PSM
‚îî‚îÄ Time-to-event question
   ‚îú‚îÄ Proportional hazards ‚Üí Cox PH
   ‚îú‚îÄ Parametric assumptions ‚Üí Weibull, Log-normal
   ‚îî‚îÄ Non-parametric ‚Üí Kaplan-Meier
```

## Diagnostic Checking

### Time Series
- Always test for stationarity (ADF, KPSS) before ARIMA
- Check ACF/PACF plots for lag selection
- Examine residual diagnostics (Ljung-Box test)
- Verify forecast accuracy on hold-out set

### Panel Data
- Run Hausman test to choose FE vs RE
- Check for serial correlation (Wooldridge test)
- Test for cross-sectional dependence
- Use clustered standard errors

### Causal Inference
- PSM: Check balance before and after matching
- IV: Test instrument strength (F-statistic >10)
- RDD: Verify no manipulation at cutoff
- Sensitivity: Run Rosenbaum bounds

### Survival Analysis
- Test proportional hazards assumption (Schoenfeld residuals)
- Check for influential observations
- Examine Kaplan-Meier curves before parametric models
- Consider time-varying covariates if needed

## Common Pitfalls

### 1. Non-Stationarity in Time Series
**Problem:** ARIMA assumes stationarity
**Solution:**
```python
from statsmodels.tsa.stattools import adfuller

# Test for unit root
result = adfuller(data['points'])
if result[1] > 0.05:
    print("Non-stationary - difference the series")
    data['points_diff'] = data['points'].diff()
```

### 2. Endogeneity in Causal Inference
**Problem:** Treatment correlated with unobserved factors
**Solution:**
- Use instrumental variables (IV)
- Apply propensity score matching (PSM)
- Run sensitivity analysis (Rosenbaum bounds)

### 3. Proportional Hazards Violation
**Problem:** Hazard ratios change over time
**Solution:**
```python
# Test PH assumption
from lifelines.statistics import proportional_hazard_test
results = proportional_hazard_test(cph, data, time_transform='rank')

if results.p_value < 0.05:
    print("PH violated - use stratification or time-varying covariates")
```

### 4. Model Convergence Failures
**Problem:** Optimization doesn't converge
**Solution:**
- Scale variables (standardize)
- Check for multicollinearity (VIF)
- Increase iterations or change optimizer
- Simplify model specification

## Performance Tips

### Large Datasets (>100K rows)
- Use vectorized operations (avoid loops)
- Consider downsampling for exploratory analysis
- Cache intermediate results
- Use parallel processing where available

### Memory Management
```python
# Process in chunks for large datasets
chunk_size = 10000
results = []
for chunk in pd.read_csv('data.csv', chunksize=chunk_size):
    result = process_chunk(chunk)
    results.append(result)
```

### Caching Results
```python
from functools import lru_cache

@lru_cache(maxsize=128)
def expensive_analysis(data_hash, method):
    # Expensive computation
    return result
```

## Interpretation Guidelines

### Statistical vs. Practical Significance
- p-value <0.05 ‚â† meaningful effect
- Always report effect sizes
- Consider confidence intervals
- Use domain knowledge

### Reporting Results
**Good Report Structure:**
1. Research question
2. Data description
3. Method justification
4. Diagnostic checks
5. Results interpretation
6. Robustness checks
7. Limitations

**Example:**
```
Research Question: Does home court advantage affect win probability?

Data: 1,230 NBA games (2022-2023 season)

Method: Propensity Score Matching (PSM)
- Treatment: Home game (vs. away)
- Outcome: Win probability
- Covariates: Team strength, opponent strength, rest days

Diagnostics:
- Balance check: Standardized differences <0.1 ‚úÖ
- Common support: 95% of observations ‚úÖ
- Sensitivity: Rosenbaum bounds [0.05, 0.15] at Œì=2

Results:
- ATT = 0.08 (95% CI: [0.04, 0.12])
- Interpretation: Home teams win 8% more often, holding team quality constant
- p-value = 0.001

Robustness:
- Kernel matching: ATT = 0.09
- Radius matching: ATT = 0.07
- Results consistent across specifications

Limitations:
- Cannot rule out all unobserved confounding
- Assumes no spillover effects
- Limited to 2022-2023 season
```

---

**Last Updated:** 2025-11-04
```

**Deliverables:**
- ‚úÖ Complete best practices guide
- ‚úÖ Method selection decision tree
- ‚úÖ Diagnostic checklists for all methods
- ‚úÖ Common pitfalls documented
- ‚úÖ Performance optimization tips

---

## üß™ **Sub-Phase C: Integration Testing (4-5 hours)**

### **1. End-to-End Workflow Tests (2 hours)**

**File:** `tests/integration/test_e2e_workflows.py`

**Goal:** Test complete analysis pipelines from data loading to results

```python
#!/usr/bin/env python3
"""
End-to-End Workflow Integration Tests

Tests complete analysis workflows: data ‚Üí analysis ‚Üí visualization ‚Üí export

Phase 1 Week 4 - Sub-Phase C: Integration Testing
"""

import pytest
import pandas as pd
import numpy as np
from mcp_server.econometric_suite import EconometricSuite

class TestPlayerAnalysisWorkflow:
    """Test complete player performance analysis workflow"""

    def test_player_performance_forecast_workflow(self):
        """
        Complete workflow: Load player data ‚Üí Test stationarity ‚Üí
        Fit ARIMA ‚Üí Generate forecast ‚Üí Evaluate accuracy
        """
        # Step 1: Load data
        data = pd.DataFrame({
            'date': pd.date_range('2020-01-01', periods=100),
            'player_id': [1]*100,
            'points': np.random.randn(100).cumsum() + 20,
            'games_played': range(1, 101)
        })

        # Step 2: Initialize suite
        suite = EconometricSuite(
            data=data,
            target='points',
            time_col='date'
        )

        # Step 3: Check stationarity
        from statsmodels.tsa.stattools import adfuller
        adf_result = adfuller(data['points'])

        # Step 4: Fit ARIMA
        if adf_result[1] > 0.05:
            # Non-stationary - use differencing
            result = suite.time_series_analysis(method='arima', order=(1,1,1))
        else:
            # Stationary
            result = suite.time_series_analysis(method='arima', order=(1,0,1))

        # Step 5: Generate forecast
        forecast = result.result.forecast(steps=10)

        # Step 6: Validate results
        assert result is not None
        assert result.result.aic is not None
        assert len(forecast) == 10
        assert all(forecast > 0)  # Points should be positive

    def test_player_comparison_workflow(self):
        """
        Compare multiple players using panel data methods
        """
        # Create multi-player data
        data = []
        for player_id in range(1, 6):  # 5 players
            for game in range(50):
                data.append({
                    'player_id': player_id,
                    'game': game,
                    'points': np.random.poisson(20) + player_id,
                    'minutes': np.random.uniform(20, 40),
                    'team_quality': np.random.uniform(0, 1)
                })
        df = pd.DataFrame(data)

        # Panel analysis
        suite = EconometricSuite(
            data=df,
            target='points',
            entity_col='player_id',
            time_col='game'
        )

        # Run fixed effects
        result = suite.panel_analysis(method='fixed_effects')

        # Validate
        assert result is not None
        assert hasattr(result.result, 'params')


class TestTeamStrategyWorkflow:
    """Test team strategy optimization workflows"""

    def test_coaching_change_impact_workflow(self):
        """
        Causal inference workflow: Define treatment ‚Üí Match teams ‚Üí
        Estimate effect ‚Üí Check sensitivity
        """
        # Create team-season data
        data = []
        for team_id in range(1, 31):  # 30 teams
            for season in range(5):
                data.append({
                    'team_id': team_id,
                    'season': season,
                    'new_coach': np.random.binomial(1, 0.3),  # 30% get new coach
                    'wins': np.random.poisson(41),
                    'roster_quality': np.random.uniform(0, 1),
                    'previous_wins': np.random.poisson(40)
                })
        df = pd.DataFrame(data)

        # Causal analysis
        suite = EconometricSuite(
            data=df,
            target='wins',
            treatment_col='new_coach'
        )

        # Run PSM
        result = suite.causal_analysis(
            method='psm',
            covariates=['roster_quality', 'previous_wins'],
            caliper=0.1
        )

        # Validate
        assert result is not None
        assert hasattr(result.result, 'att')
        assert hasattr(result.result, 'p_value')


class TestCareerArcWorkflow:
    """Test career longevity modeling workflows"""

    def test_career_longevity_workflow(self):
        """
        Survival analysis workflow: Load career data ‚Üí Fit Cox ‚Üí
        Interpret hazards ‚Üí Predict survival
        """
        # Create career data
        data = []
        for player_id in range(1, 101):
            data.append({
                'player_id': player_id,
                'career_length': np.random.exponential(5),
                'retired': np.random.binomial(1, 0.7),
                'draft_pick': np.random.uniform(1, 60),
                'injuries': np.random.poisson(2),
                'position': np.random.choice(['PG', 'SG', 'SF', 'PF', 'C'])
            })
        df = pd.DataFrame(data)

        # Survival analysis
        suite = EconometricSuite(
            data=df,
            target='career_length',
            duration_col='career_length',
            event_col='retired'
        )

        # Run Cox PH
        result = suite.survival_analysis(
            method='cox',
            covariates=['draft_pick', 'injuries']
        )

        # Validate
        assert result is not None
        assert hasattr(result.result, 'hazard_ratios')


class TestMultiMethodComparison:
    """Test workflows that compare multiple methods"""

    def test_method_comparison_workflow(self):
        """
        Compare multiple time series methods and select best
        """
        # Generate time series data
        data = pd.DataFrame({
            'date': pd.date_range('2020-01-01', periods=200),
            'points': np.random.randn(200).cumsum() + 25
        })

        suite = EconometricSuite(
            data=data,
            target='points',
            time_col='date'
        )

        # Compare methods
        methods = [
            {'category': 'time_series', 'method': 'arima', 'params': {'order': (1,1,1)}},
            {'category': 'time_series', 'method': 'arima', 'params': {'order': (2,1,1)}},
            {'category': 'advanced_time_series', 'method': 'kalman', 'params': {}}
        ]

        comparison = suite.compare_methods(methods, metric='aic')

        # Validate
        assert comparison is not None
        assert len(comparison) == 3
        assert 'aic' in comparison.columns


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

**Deliverables:**
- ‚úÖ 15+ end-to-end workflow tests
- ‚úÖ Player analysis workflows tested
- ‚úÖ Team strategy workflows tested
- ‚úÖ Career arc workflows tested
- ‚úÖ Multi-method comparison tested

### **2. Cross-Module Integration Tests (1.5 hours)**

**File:** `tests/integration/test_cross_module.py`

**Goal:** Test interactions between different modules

```python
def test_time_series_to_panel_workflow():
    """Test using time series results in panel analysis"""
    # Generate panel data
    # Run time series on each entity
    # Use residuals in panel model
    # Validate integration

def test_causal_with_survival_workflow():
    """Test causal inference with survival outcomes"""
    # Treatment affects survival
    # PSM to balance
    # Cox PH on matched sample
    # Compare ATT

def test_bayesian_ensemble_workflow():
    """Test Bayesian model averaging across methods"""
    # Fit multiple Bayesian models
    # Compute weights (WAIC)
    # Ensemble predictions
    # Validate performance
```

**Deliverables:**
- ‚úÖ 10+ cross-module integration tests
- ‚úÖ Module interactions validated
- ‚úÖ Data flow verified

### **3. Performance Regression Tests (1 hour)**

**File:** `tests/performance/test_regression.py`

**Goal:** Ensure no performance degradation

```python
def test_arima_performance_baseline():
    """Ensure ARIMA doesn't regress below baseline"""
    data = generate_data(size=10000)

    import time
    start = time.time()
    result = fit_arima(data)
    elapsed = time.time() - start

    # Should complete in <5 seconds for 10K rows
    assert elapsed < 5.0
```

**Deliverables:**
- ‚úÖ Performance baselines for all methods
- ‚úÖ Automated regression detection
- ‚úÖ Performance documentation

---

## üìä Success Criteria

### Sub-Phase A: Test Fixes & Stabilization
- [x] All 179 tests passing (100% pass rate)
- [x] >95% code coverage on all modules
- [x] Performance baselines established
- [x] No regressions introduced

### Sub-Phase B: Comprehensive Documentation
- [x] Quick start guide complete
- [x] API reference for all 26 methods
- [x] Best practices guide
- [x] All examples working

### Sub-Phase C: Integration Testing
- [x] 25+ integration tests passing
- [x] End-to-end workflows validated
- [x] Cross-module interactions tested
- [x] Performance regression tests automated

---

## üéØ Timeline

**Week 4 Day 1:** Sub-Phase A (Test Fixes & Stabilization) - 3-4 hours
**Week 4 Day 2:** Sub-Phase B (Comprehensive Documentation) - 5-7 hours
**Week 4 Day 3:** Sub-Phase C (Integration Testing) - 4-5 hours

**Target Completion:** End of Week 4

---

## üìÅ Deliverables Summary

**Bug Fixes:** 12 test failures resolved
**Documentation:** 3 comprehensive guides (Quick Start, API Reference, Best Practices)
**Tests:** 25+ integration tests
**Performance:** Benchmarks for all 26 methods
**Total Files:** ~10 new/modified files

---

## üìà Expected Outcomes

Upon completion of Phase 1 Week 4, the platform will have:

‚úÖ **Quality**
- 100% test pass rate (179/179 tests)
- >95% code coverage
- Performance baselines established
- Integration testing complete

‚úÖ **Documentation**
- Comprehensive quick start guide
- Complete API reference
- Best practices documented
- All examples working

‚úÖ **Production Readiness**
- All bugs fixed
- Exception handling validated
- Performance optimized
- Documentation complete

---

**Status:** Ready to begin Sub-Phase A
**Created:** 2025-11-04
**Phase 1 Week 3 Status:** ‚úÖ Complete (100%)
**Phase 1 Week 4 Status:** ‚è≥ Ready to start (0%)