{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Performance Trend Analysis\n",
    "\n",
    "This notebook demonstrates how to use the NBA MCP Econometric Suite to analyze player performance trends over time using advanced time series methods.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Load and prepare player scoring data across multiple seasons\n",
    "2. Test for stationarity using ADF and KPSS tests\n",
    "3. Fit ARIMA models for forecasting\n",
    "4. Apply Kalman filtering for real-time performance tracking\n",
    "5. Use structural decomposition to separate level, trend, and seasonal components\n",
    "6. Compare multiple methods using the EconometricSuite\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy matplotlib seaborn statsmodels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import econometric modules\n",
    "from mcp_server.time_series import TimeSeriesAnalyzer\n",
    "from mcp_server.advanced_time_series import AdvancedTimeSeriesAnalyzer\n",
    "from mcp_server.econometric_suite import EconometricSuite\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Player Performance Data\n",
    "\n",
    "For this demonstration, we'll generate synthetic player performance data that mimics real NBA statistics:\n",
    "- Upward trend (player improvement)\n",
    "- Seasonal pattern (playoff performance boost)\n",
    "- Random noise (game-to-game variability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_player_performance_data(n_games=200, player_name=\"LeBron James\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic player performance data with trend, seasonality, and noise.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_games : int\n",
    "        Number of games to simulate\n",
    "    player_name : str\n",
    "        Player name for metadata\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with date, points_per_game, and other metrics\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate dates (2 games per week for ~2 seasons)\n",
    "    start_date = datetime(2023, 10, 1)\n",
    "    dates = [start_date + timedelta(days=i*3) for i in range(n_games)]\n",
    "    \n",
    "    # Components of player performance\n",
    "    # 1. Base level (starting performance)\n",
    "    base_level = 22.0\n",
    "    \n",
    "    # 2. Linear trend (player improvement over time)\n",
    "    trend = np.linspace(0, 5, n_games)  # +5 PPG improvement over period\n",
    "    \n",
    "    # 3. Seasonal component (playoff boost every ~41 games)\n",
    "    seasonal = 3 * np.sin(2 * np.pi * np.arange(n_games) / 41)\n",
    "    \n",
    "    # 4. Cyclical component (hot/cold streaks)\n",
    "    cyclical = 2 * np.sin(2 * np.pi * np.arange(n_games) / 15)\n",
    "    \n",
    "    # 5. Random noise (game-to-game variability)\n",
    "    noise = np.random.normal(0, 2.5, n_games)\n",
    "    \n",
    "    # Combine components\n",
    "    ppg = base_level + trend + seasonal + cyclical + noise\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'player_name': player_name,\n",
    "        'points_per_game': ppg,\n",
    "        'season': ['2023-24' if d < datetime(2024, 6, 1) else '2024-25' for d in dates],\n",
    "        'game_number': range(1, n_games + 1)\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data for LeBron James\n",
    "player_data = generate_player_performance_data(n_games=200, player_name=\"LeBron James\")\n",
    "\n",
    "print(f\"Generated {len(player_data)} games of data\")\n",
    "print(f\"Date range: {player_data['date'].min()} to {player_data['date'].max()}\")\n",
    "print(f\"\\nFirst 5 games:\")\n",
    "player_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(player_data['date'], player_data['points_per_game'], marker='o', \n",
    "        linestyle='-', linewidth=1, markersize=3, alpha=0.7)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Points Per Game', fontsize=12)\n",
    "ax.set_title('LeBron James - Points Per Game Over Time', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(player_data['points_per_game'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stationarity Testing\n",
    "\n",
    "Before fitting time series models, we need to test if the data is stationary (constant mean and variance over time).\n",
    "\n",
    "We'll use:\n",
    "- **ADF Test** (Augmented Dickey-Fuller): Tests for unit root (non-stationarity)\n",
    "- **KPSS Test**: Tests for stationarity around a deterministic trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TimeSeriesAnalyzer\n",
    "ts_data = player_data.set_index('date')['points_per_game']\n",
    "analyzer = TimeSeriesAnalyzer(data=ts_data, freq='D')\n",
    "\n",
    "# Run ADF test\n",
    "print(\"=\" * 60)\n",
    "print(\"AUGMENTED DICKEY-FULLER TEST\")\n",
    "print(\"=\" * 60)\n",
    "adf_result = analyzer.adf_test()\n",
    "print(f\"ADF Statistic: {adf_result['adf_statistic']:.4f}\")\n",
    "print(f\"P-value: {adf_result['p_value']:.4f}\")\n",
    "print(f\"Critical Values:\")\n",
    "for key, value in adf_result['critical_values'].items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "print(f\"\\nConclusion: {'Stationary' if adf_result['stationary'] else 'Non-Stationary'}\")\n",
    "print(f\"Interpretation: {adf_result['interpretation']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KPSS TEST\")\n",
    "print(\"=\" * 60)\n",
    "kpss_result = analyzer.kpss_test()\n",
    "print(f\"KPSS Statistic: {kpss_result['kpss_statistic']:.4f}\")\n",
    "print(f\"P-value: {kpss_result['p_value']:.4f}\")\n",
    "print(f\"Critical Values:\")\n",
    "for key, value in kpss_result['critical_values'].items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "print(f\"\\nConclusion: {'Stationary' if kpss_result['stationary'] else 'Non-Stationary'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Seasonal Decomposition\n",
    "\n",
    "Break down the time series into:\n",
    "- **Trend**: Long-term movement\n",
    "- **Seasonal**: Repeating patterns\n",
    "- **Residual**: Random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform seasonal decomposition\n",
    "decomposition = analyzer.decompose(model='additive', period=41)  # 41 games ~ half season\n",
    "\n",
    "# Visualize components\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "\n",
    "# Original\n",
    "axes[0].plot(decomposition['observed'].index, decomposition['observed'], color='blue')\n",
    "axes[0].set_ylabel('Original', fontsize=11)\n",
    "axes[0].set_title('Seasonal Decomposition - LeBron James PPG', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trend\n",
    "axes[1].plot(decomposition['trend'].index, decomposition['trend'], color='green')\n",
    "axes[1].set_ylabel('Trend', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Seasonal\n",
    "axes[2].plot(decomposition['seasonal'].index, decomposition['seasonal'], color='orange')\n",
    "axes[2].set_ylabel('Seasonal', fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual\n",
    "axes[3].plot(decomposition['resid'].index, decomposition['resid'], color='red', alpha=0.6)\n",
    "axes[3].set_ylabel('Residual', fontsize=11)\n",
    "axes[3].set_xlabel('Date', fontsize=11)\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDecomposition Statistics:\")\n",
    "print(f\"Trend contribution: {decomposition['trend'].std():.2f}\")\n",
    "print(f\"Seasonal contribution: {decomposition['seasonal'].std():.2f}\")\n",
    "print(f\"Residual contribution: {decomposition['resid'].dropna().std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ARIMA Modeling and Forecasting\n",
    "\n",
    "Fit an ARIMA model to forecast future performance.\n",
    "\n",
    "We'll use Auto-ARIMA to automatically select the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-select best ARIMA model\n",
    "print(\"Fitting Auto-ARIMA model...\")\n",
    "print(\"This may take a minute as it tests multiple parameter combinations.\\n\")\n",
    "\n",
    "arima_model = analyzer.auto_arima(seasonal=False, max_p=3, max_q=3, max_d=2)\n",
    "\n",
    "print(f\"Best ARIMA Order: {arima_model['order']}\")\n",
    "print(f\"AIC: {arima_model['aic']:.2f}\")\n",
    "print(f\"BIC: {arima_model['bic']:.2f}\")\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(arima_model['model_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast next 20 games\n",
    "forecast_result = analyzer.forecast(model=arima_model, steps=20)\n",
    "\n",
    "# Visualize forecast\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Historical data\n",
    "ax.plot(ts_data.index, ts_data, label='Historical', color='blue', linewidth=2)\n",
    "\n",
    "# Forecast\n",
    "forecast_dates = pd.date_range(start=ts_data.index[-1] + timedelta(days=3), \n",
    "                                periods=20, freq='3D')\n",
    "ax.plot(forecast_dates, forecast_result['forecast'], \n",
    "        label='Forecast', color='red', linewidth=2, linestyle='--')\n",
    "\n",
    "# Confidence interval\n",
    "ax.fill_between(forecast_dates,\n",
    "                forecast_result['lower_bound'],\n",
    "                forecast_result['upper_bound'],\n",
    "                alpha=0.2, color='red', label='95% Confidence Interval')\n",
    "\n",
    "ax.axvline(x=ts_data.index[-1], color='gray', linestyle=':', alpha=0.7)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Points Per Game', fontsize=12)\n",
    "ax.set_title('ARIMA Forecast - LeBron James PPG', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nForecast Statistics:\")\n",
    "print(f\"Mean forecast: {forecast_result['forecast'].mean():.2f} PPG\")\n",
    "print(f\"Forecast range: [{forecast_result['forecast'].min():.2f}, {forecast_result['forecast'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Kalman Filtering for Real-Time Tracking\n",
    "\n",
    "Use Kalman filters to track the latent (true) performance level in real-time, filtering out noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Advanced Time Series Analyzer\n",
    "adv_analyzer = AdvancedTimeSeriesAnalyzer(data=ts_data.values)\n",
    "\n",
    "# Fit Kalman filter (local level model)\n",
    "print(\"Fitting Kalman Filter (Local Level Model)...\\n\")\n",
    "kalman_result = adv_analyzer.fit_kalman_filter(model='local_level')\n",
    "\n",
    "print(f\"Model: Local Level Kalman Filter\")\n",
    "print(f\"Log-Likelihood: {kalman_result['log_likelihood']:.2f}\")\n",
    "print(f\"AIC: {kalman_result['aic']:.2f}\")\n",
    "print(f\"\\nEstimated Parameters:\")\n",
    "for param, value in kalman_result['parameters'].items():\n",
    "    print(f\"  {param}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Kalman filtered states\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Raw observations\n",
    "ax.plot(ts_data.index, ts_data, label='Observed PPG', \n",
    "        color='blue', alpha=0.4, linewidth=1.5)\n",
    "\n",
    "# Filtered state (smoothed estimate)\n",
    "ax.plot(ts_data.index, kalman_result['filtered_state'], \n",
    "        label='Kalman Filtered State', color='red', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Points Per Game', fontsize=12)\n",
    "ax.set_title('Kalman Filter - True Performance Level Estimation', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate how much noise was filtered out\n",
    "noise_reduction = ts_data.std() - pd.Series(kalman_result['filtered_state']).std()\n",
    "print(f\"\\nNoise Reduction:\")\n",
    "print(f\"Original std dev: {ts_data.std():.2f}\")\n",
    "print(f\"Filtered std dev: {pd.Series(kalman_result['filtered_state']).std():.2f}\")\n",
    "print(f\"Reduction: {noise_reduction:.2f} ({(noise_reduction/ts_data.std())*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Structural Time Series Decomposition\n",
    "\n",
    "Use state-space models to decompose the series into level, trend, seasonal, and cycle components simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit structural time series model\n",
    "print(\"Fitting Structural Time Series Model...\\n\")\n",
    "structural_result = adv_analyzer.fit_structural_ts(\n",
    "    level=True, \n",
    "    trend=True, \n",
    "    seasonal=41,  # Half-season periodicity\n",
    "    cycle=True\n",
    ")\n",
    "\n",
    "print(f\"Model: Structural Time Series\")\n",
    "print(f\"Components: Level + Trend + Seasonal(41) + Cycle\")\n",
    "print(f\"Log-Likelihood: {structural_result['log_likelihood']:.2f}\")\n",
    "print(f\"AIC: {structural_result['aic']:.2f}\")\n",
    "print(f\"BIC: {structural_result['bic']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize structural components\n",
    "fig, axes = plt.subplots(5, 1, figsize=(14, 12))\n",
    "\n",
    "# Observed\n",
    "axes[0].plot(ts_data.index, ts_data, color='blue')\n",
    "axes[0].set_ylabel('Observed', fontsize=10)\n",
    "axes[0].set_title('Structural Time Series Decomposition', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Level\n",
    "axes[1].plot(ts_data.index, structural_result['level'], color='green')\n",
    "axes[1].set_ylabel('Level', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Trend\n",
    "axes[2].plot(ts_data.index, structural_result['trend'], color='purple')\n",
    "axes[2].set_ylabel('Trend', fontsize=10)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Seasonal\n",
    "axes[3].plot(ts_data.index, structural_result['seasonal'], color='orange')\n",
    "axes[3].set_ylabel('Seasonal', fontsize=10)\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "# Cycle\n",
    "axes[4].plot(ts_data.index, structural_result['cycle'], color='brown')\n",
    "axes[4].set_ylabel('Cycle', fontsize=10)\n",
    "axes[4].set_xlabel('Date', fontsize=11)\n",
    "axes[4].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nComponent Variability:\")\n",
    "print(f\"Level std: {pd.Series(structural_result['level']).std():.2f}\")\n",
    "print(f\"Trend std: {pd.Series(structural_result['trend']).std():.2f}\")\n",
    "print(f\"Seasonal std: {pd.Series(structural_result['seasonal']).std():.2f}\")\n",
    "print(f\"Cycle std: {pd.Series(structural_result['cycle']).std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Unified Analysis with EconometricSuite\n",
    "\n",
    "Use the EconometricSuite to automatically detect the data structure and compare multiple methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Suite (needs DataFrame with date column)\n",
    "suite_data = player_data[['date', 'points_per_game']].copy()\n",
    "suite_data = suite_data.set_index('date')\n",
    "\n",
    "# Initialize EconometricSuite\n",
    "suite = EconometricSuite(\n",
    "    data=suite_data,\n",
    "    target='points_per_game',\n",
    "    time_col=None  # Already set as index\n",
    ")\n",
    "\n",
    "print(\"EconometricSuite Initialized\")\n",
    "print(f\"Data structure detected: {suite.data_structure}\")\n",
    "print(f\"Recommended methods: {suite.recommended_methods}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-analyze with best method\n",
    "auto_result = suite.analyze(method='auto')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AUTO-ANALYSIS RESULT\")\n",
    "print(\"=\" * 60)\n",
    "print(auto_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple methods\n",
    "print(\"Comparing multiple time series methods...\\n\")\n",
    "\n",
    "comparison = suite.compare_methods(\n",
    "    methods=[\n",
    "        {'category': 'time_series', 'method': 'arima', 'params': {'order': (1, 1, 1)}},\n",
    "        {'category': 'time_series', 'method': 'auto_arima', 'params': {}},\n",
    "        {'category': 'advanced_time_series', 'method': 'kalman', 'params': {'model': 'local_level'}}\n",
    "    ],\n",
    "    metric='aic'\n",
    ")\n",
    "\n",
    "print(\"\\nMethod Comparison Results:\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Insights\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Stationarity**: The data shows non-stationary behavior due to the trend component\n",
    "2. **Components**: \n",
    "   - Strong upward trend indicating player improvement\n",
    "   - Seasonal pattern aligned with half-season (playoff) cycles\n",
    "   - Cyclical hot/cold streaks\n",
    "3. **Forecasting**: ARIMA provides reasonable point forecasts with uncertainty quantification\n",
    "4. **Real-time Tracking**: Kalman filter effectively reduces noise and reveals true performance level\n",
    "5. **Structural Model**: Decomposes performance into interpretable components\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **For Forecasting**: Use ARIMA for short-term predictions with confidence intervals\n",
    "2. **For Real-Time Monitoring**: Use Kalman filter to track current performance level\n",
    "3. **For Understanding Patterns**: Use structural decomposition to analyze long-term trends\n",
    "4. **For Model Selection**: Use EconometricSuite to compare methods and select best approach\n",
    "\n",
    "### NBA Applications\n",
    "\n",
    "- **Player Development**: Track improvement trends over seasons\n",
    "- **Injury Recovery**: Monitor return to form after injuries\n",
    "- **Contract Valuation**: Project future performance for contract negotiations\n",
    "- **Fantasy Basketball**: Forecast upcoming game performance\n",
    "- **Coaching Decisions**: Identify hot/cold streaks for lineup optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Explore **Notebook 2**: Career Longevity Modeling with Survival Analysis\n",
    "- Explore **Notebook 3**: Coaching Change Impact with Causal Inference\n",
    "- Try with real NBA data from the MCP server\n",
    "- Extend analysis to compare multiple players\n",
    "- Add Markov switching models for regime detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
