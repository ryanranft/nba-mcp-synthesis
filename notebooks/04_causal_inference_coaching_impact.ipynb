{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Inference: Measuring Coaching Change Impact\n",
    "\n",
    "**Business Question:** Did hiring a new coach actually improve team performance, or was it just chance?\n",
    "\n",
    "**The Challenge:** Correlation ‚â† Causation. Teams often hire new coaches when struggling, so performance improvements might be:\n",
    "- Natural regression to the mean\n",
    "- Player roster changes\n",
    "- Schedule difficulty changes\n",
    "- Or... genuine coaching impact?\n",
    "\n",
    "**What You'll Learn:**\n",
    "- Propensity Score Matching (PSM) to find comparable control teams\n",
    "- Difference-in-Differences (DiD) to isolate treatment effects\n",
    "- Instrumental Variables (IV) to handle endogeneity\n",
    "- Regression Discontinuity Design (RDD) for natural experiments\n",
    "\n",
    "**Methods Covered:**\n",
    "1. `CausalInferenceAnalyzer.propensity_score_matching()`\n",
    "2. `CausalInferenceAnalyzer.difference_in_differences()`\n",
    "3. `CausalInferenceAnalyzer.instrumental_variables()`\n",
    "4. `CausalInferenceAnalyzer.regression_discontinuity()`\n",
    "\n",
    "**Performance:** All methods <500ms\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import causal inference module\n",
    "from mcp_server.causal_inference import CausalInferenceAnalyzer\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Team Performance Data with Coaching Changes\n",
    "\n",
    "**Scenario:** \n",
    "- 30 NBA teams tracked over 2 seasons (164 games each)\n",
    "- 5 teams hire new coaches at midseason (after game 41)\n",
    "- We want to measure if coaching changes caused performance improvements\n",
    "\n",
    "**Confounders to Control:**\n",
    "- Pre-treatment performance (struggling teams more likely to change coaches)\n",
    "- Team payroll (richer teams can hire better coaches)\n",
    "- Player injuries\n",
    "- Schedule strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_team_data(n_teams=30, n_games=164, n_treatment_teams=5):\n",
    "    \"\"\"\n",
    "    Generate synthetic team data with coaching changes.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # Select which teams get new coaches (struggling teams more likely)\n",
    "    treatment_teams = []\n",
    "    \n",
    "    for team_id in range(n_teams):\n",
    "        # Team characteristics (time-invariant)\n",
    "        team_quality = np.random.normal(50, 10)  # True baseline win%\n",
    "        payroll = np.random.normal(120, 30)  # Millions\n",
    "        \n",
    "        # Struggling teams more likely to change coaches\n",
    "        coach_change_prob = 0.3 if team_quality < 45 else 0.05\n",
    "        gets_new_coach = (len(treatment_teams) < n_treatment_teams and \n",
    "                         np.random.random() < coach_change_prob)\n",
    "        \n",
    "        if gets_new_coach:\n",
    "            treatment_teams.append(team_id)\n",
    "        \n",
    "        # Generate game-by-game data\n",
    "        for game in range(n_games):\n",
    "            # Time period (pre/post coaching change)\n",
    "            post_change = (game >= 41) if gets_new_coach else False\n",
    "            \n",
    "            # Performance determinants\n",
    "            base_performance = team_quality\n",
    "            payroll_effect = (payroll - 120) * 0.1  # Richer teams slightly better\n",
    "            injury_shock = np.random.normal(0, 5)  # Random injuries\n",
    "            \n",
    "            # TRUE coaching effect (if any)\n",
    "            # Let's say new coaches improve win% by 5 points on average\n",
    "            coaching_effect = 5 if post_change else 0\n",
    "            \n",
    "            # Regression to mean (struggling teams tend to improve anyway)\n",
    "            rtm_effect = (50 - team_quality) * 0.1 if game >= 41 else 0\n",
    "            \n",
    "            # Observed win% for this game\n",
    "            win_pct = (base_performance + payroll_effect + injury_shock + \n",
    "                      coaching_effect + rtm_effect)\n",
    "            win_pct = np.clip(win_pct, 0, 100)\n",
    "            \n",
    "            # Did they win?\n",
    "            won = 1 if np.random.random() < (win_pct / 100) else 0\n",
    "            \n",
    "            data.append({\n",
    "                'team_id': team_id,\n",
    "                'game': game,\n",
    "                'season_half': 'second' if game >= 41 else 'first',\n",
    "                'treatment': 1 if gets_new_coach else 0,\n",
    "                'post': 1 if post_change else 0,\n",
    "                'won': won,\n",
    "                'win_pct': win_pct,\n",
    "                'team_quality': team_quality,\n",
    "                'payroll': payroll,\n",
    "                'injury_shock': injury_shock\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df, treatment_teams\n",
    "\n",
    "# Generate data\n",
    "df, treatment_teams = generate_team_data(n_teams=30, n_games=82, n_treatment_teams=5)\n",
    "\n",
    "print(f\"Generated data for {df['team_id'].nunique()} teams over {df['game'].nunique()} games\")\n",
    "print(f\"\\nTeams with coaching changes: {len(treatment_teams)}\")\n",
    "print(f\"Treatment team IDs: {treatment_teams}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nAverage win% by group:\")\n",
    "summary = df.groupby(['treatment', 'post']).agg({\n",
    "    'won': 'mean',\n",
    "    'team_id': 'nunique'\n",
    "}).round(3)\n",
    "summary.columns = ['Win Rate', 'N Teams']\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive Comparison (Wrong!)\n",
    "\n",
    "**Common Mistake:** Just compare before/after win rates for teams that changed coaches.\n",
    "\n",
    "**Problem:** This confounds:\n",
    "- True coaching effect\n",
    "- Regression to the mean\n",
    "- League-wide trends\n",
    "- Selection bias (struggling teams more likely to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive before/after comparison for treatment teams only\n",
    "treatment_df = df[df['treatment'] == 1].copy()\n",
    "\n",
    "naive_before = treatment_df[treatment_df['post'] == 0]['won'].mean()\n",
    "naive_after = treatment_df[treatment_df['post'] == 1]['won'].mean()\n",
    "naive_effect = naive_after - naive_before\n",
    "\n",
    "print(\"‚ùå NAIVE ANALYSIS (Biased):\")\n",
    "print(f\"   Win rate BEFORE coaching change: {naive_before:.3f}\")\n",
    "print(f\"   Win rate AFTER coaching change:  {naive_after:.3f}\")\n",
    "print(f\"   Naive effect estimate: {naive_effect:+.3f} ({naive_effect*82:+.1f} wins per season)\")\n",
    "print(f\"\\n   ‚ö†Ô∏è  This is BIASED because it ignores:\")\n",
    "print(f\"      - Regression to the mean\")\n",
    "print(f\"      - League-wide trends\")\n",
    "print(f\"      - Selection bias\")\n",
    "print(f\"\\n   We need causal inference methods to get the TRUE effect!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Method 1: Propensity Score Matching (PSM)\n",
    "\n",
    "**Idea:** Match each treated team with a similar control team based on pre-treatment characteristics.\n",
    "\n",
    "**How it works:**\n",
    "1. Estimate probability (propensity) of treatment based on covariates\n",
    "2. Match treated units to controls with similar propensities\n",
    "3. Compare outcomes only among matched pairs\n",
    "\n",
    "**Why it helps:** Controls for selection bias (struggling teams choosing to change coaches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for PSM (need pre-treatment characteristics)\n",
    "# Aggregate to team level with pre-treatment covariates\n",
    "team_level = df.groupby('team_id').agg({\n",
    "    'treatment': 'first',\n",
    "    'team_quality': 'first',\n",
    "    'payroll': 'first',\n",
    "    'won': lambda x: x.iloc[:41].mean()  # Pre-treatment win rate\n",
    "}).reset_index()\n",
    "team_level.columns = ['team_id', 'treatment', 'team_quality', 'payroll', 'pre_win_rate']\n",
    "\n",
    "# Post-treatment outcomes\n",
    "post_outcomes = df[df['post'] == 1].groupby('team_id')['won'].mean().reset_index()\n",
    "post_outcomes.columns = ['team_id', 'post_win_rate']\n",
    "team_level = team_level.merge(post_outcomes, on='team_id')\n",
    "\n",
    "print(\"Team-level data for PSM:\")\n",
    "print(team_level.head())\n",
    "\n",
    "# Initialize causal inference analyzer\n",
    "causal_analyzer = CausalInferenceAnalyzer(\n",
    "    data=team_level,\n",
    "    treatment_col='treatment',\n",
    "    outcome_col='post_win_rate'\n",
    ")\n",
    "\n",
    "# Run propensity score matching\n",
    "psm_result = causal_analyzer.propensity_score_matching(\n",
    "    covariates=['pre_win_rate', 'team_quality', 'payroll'],\n",
    "    method='nearest',\n",
    "    caliper=0.2\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì PROPENSITY SCORE MATCHING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAverage Treatment Effect (ATE): {psm_result['ate']:+.3f}\")\n",
    "print(f\"95% Confidence Interval: [{psm_result['ci_lower']:+.3f}, {psm_result['ci_upper']:+.3f}]\")\n",
    "print(f\"P-value: {psm_result['p_value']:.4f}\")\n",
    "print(f\"\\nMatched pairs: {psm_result['n_matched']}\")\n",
    "print(f\"\\nüìä Interpretation:\")\n",
    "if psm_result['p_value'] < 0.05:\n",
    "    wins_per_season = psm_result['ate'] * 82\n",
    "    print(f\"   ‚úì Coaching change caused a {psm_result['ate']:+.3f} change in win rate\")\n",
    "    print(f\"   ‚úì This translates to {wins_per_season:+.1f} wins per season\")\n",
    "    print(f\"   ‚úì Effect is statistically significant (p={psm_result['p_value']:.4f})\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  No significant effect detected (p={psm_result['p_value']:.4f})\")\n",
    "    print(f\"   ‚ö†Ô∏è  Could be due to small sample size or genuine null effect\")\n",
    "\n",
    "print(f\"\\n‚ö° Performance: {psm_result['execution_time']*1000:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Method 2: Difference-in-Differences (DiD)\n",
    "\n",
    "**Idea:** Compare the change over time in treated groups vs. control groups.\n",
    "\n",
    "**Formula:** \n",
    "```\n",
    "DiD = (Treated_After - Treated_Before) - (Control_After - Control_Before)\n",
    "```\n",
    "\n",
    "**Why it helps:** \n",
    "- Controls for time-invariant team differences\n",
    "- Controls for league-wide time trends\n",
    "- Isolates the treatment effect\n",
    "\n",
    "**Assumption:** Parallel trends (without treatment, both groups would have trended similarly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for DiD (need panel structure)\n",
    "# Aggregate to team-period level\n",
    "did_data = df.groupby(['team_id', 'treatment', 'post']).agg({\n",
    "    'won': 'mean',\n",
    "    'team_quality': 'first',\n",
    "    'payroll': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"Panel data for DiD:\")\n",
    "print(did_data.head(10))\n",
    "\n",
    "# Initialize causal inference analyzer with panel data\n",
    "did_analyzer = CausalInferenceAnalyzer(\n",
    "    data=did_data,\n",
    "    treatment_col='treatment',\n",
    "    outcome_col='won'\n",
    ")\n",
    "\n",
    "# Run difference-in-differences\n",
    "did_result = did_analyzer.difference_in_differences(\n",
    "    time_col='post',\n",
    "    entity_col='team_id',\n",
    "    covariates=['team_quality', 'payroll']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì DIFFERENCE-IN-DIFFERENCES RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDiD Estimate: {did_result['did_estimate']:+.3f}\")\n",
    "print(f\"Standard Error: {did_result['std_error']:.4f}\")\n",
    "print(f\"95% Confidence Interval: [{did_result['ci_lower']:+.3f}, {did_result['ci_upper']:+.3f}]\")\n",
    "print(f\"P-value: {did_result['p_value']:.4f}\")\n",
    "\n",
    "# Show the 2x2 table\n",
    "print(f\"\\nüìä DiD Decomposition:\")\n",
    "means = did_data.groupby(['treatment', 'post'])['won'].mean().unstack()\n",
    "print(\"\\n        Before    After     Change\")\n",
    "print(f\"Treat:  {means.loc[1, 0]:.3f}    {means.loc[1, 1]:.3f}    {means.loc[1, 1] - means.loc[1, 0]:+.3f}\")\n",
    "print(f\"Control:{means.loc[0, 0]:.3f}    {means.loc[0, 1]:.3f}    {means.loc[0, 1] - means.loc[0, 0]:+.3f}\")\n",
    "print(f\"                           DiD: {did_result['did_estimate']:+.3f}\")\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "if did_result['p_value'] < 0.05:\n",
    "    wins_per_season = did_result['did_estimate'] * 82\n",
    "    print(f\"   ‚úì After controlling for time trends, coaching change caused\")\n",
    "    print(f\"     a {did_result['did_estimate']:+.3f} improvement in win rate\")\n",
    "    print(f\"   ‚úì This equals {wins_per_season:+.1f} additional wins per season\")\n",
    "    print(f\"   ‚úì Statistically significant (p={did_result['p_value']:.4f})\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  No significant effect after controlling for time trends\")\n",
    "\n",
    "print(f\"\\n‚ö° Performance: {did_result['execution_time']*1000:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize DiD: Parallel Trends\n",
    "\n",
    "**Key Assumption Check:** Do treatment and control groups have parallel trends before treatment?\n",
    "\n",
    "If trends diverge before treatment, DiD estimates are biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling win rates over time\n",
    "rolling_data = []\n",
    "for team_id in df['team_id'].unique():\n",
    "    team_data = df[df['team_id'] == team_id].sort_values('game')\n",
    "    treatment = team_data['treatment'].iloc[0]\n",
    "    \n",
    "    # 10-game rolling average\n",
    "    team_data['rolling_win_rate'] = team_data['won'].rolling(window=10, min_periods=1).mean()\n",
    "    \n",
    "    rolling_data.append(team_data)\n",
    "\n",
    "rolling_df = pd.concat(rolling_data)\n",
    "\n",
    "# Average by treatment group and game\n",
    "trends = rolling_df.groupby(['game', 'treatment'])['rolling_win_rate'].mean().reset_index()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Treatment group\n",
    "treatment_trend = trends[trends['treatment'] == 1]\n",
    "ax.plot(treatment_trend['game'], treatment_trend['rolling_win_rate'], \n",
    "        'b-', linewidth=2.5, label='Treatment (New Coach)', marker='o', markersize=3)\n",
    "\n",
    "# Control group\n",
    "control_trend = trends[trends['treatment'] == 0]\n",
    "ax.plot(control_trend['game'], control_trend['rolling_win_rate'], \n",
    "        'r-', linewidth=2.5, label='Control (Same Coach)', marker='s', markersize=3)\n",
    "\n",
    "# Mark treatment time\n",
    "ax.axvline(x=41, color='gray', linestyle='--', linewidth=2, label='Coaching Change')\n",
    "ax.text(41, ax.get_ylim()[1]*0.95, 'Treatment\\nStarts', \n",
    "        ha='center', va='top', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Annotations\n",
    "ax.fill_between([0, 41], *ax.get_ylim(), alpha=0.1, color='gray', label='Pre-Treatment')\n",
    "ax.fill_between([41, 82], *ax.get_ylim(), alpha=0.1, color='yellow', label='Post-Treatment')\n",
    "\n",
    "ax.set_xlabel('Game Number', fontsize=12)\n",
    "ax.set_ylabel('Win Rate (10-game rolling average)', fontsize=12)\n",
    "ax.set_title('Difference-in-Differences: Parallel Trends Check', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0.3, 0.7])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Parallel Trends Assessment:\")\n",
    "print(\"   ‚úì Before treatment (games 0-40): Check if lines are parallel\")\n",
    "print(\"   ‚úì After treatment (games 41-82): Any divergence = treatment effect\")\n",
    "print(\"   ‚ö†Ô∏è  If pre-treatment trends differ, DiD assumption violated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Method 3: Instrumental Variables (IV)\n",
    "\n",
    "**Problem:** What if coaching changes are endogenous?\n",
    "- Good coaches go to good teams\n",
    "- Or teams hire new coaches after getting better players\n",
    "\n",
    "**Solution:** Find an \"instrument\" - a variable that:\n",
    "1. Affects treatment (coaching change)\n",
    "2. Doesn't directly affect outcome (only through treatment)\n",
    "\n",
    "**Example Instrument:** Coach contract expiration\n",
    "- Affects likelihood of coaching change (contractual reasons)\n",
    "- Doesn't directly affect team performance (just timing)\n",
    "\n",
    "**Note:** This is advanced - often hard to find good instruments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate instrument: coach contract expiration\n",
    "# (Random but correlated with coaching changes)\n",
    "team_level['contract_expiring'] = np.random.binomial(1, 0.3, len(team_level))\n",
    "# Make instrument correlated with treatment\n",
    "team_level.loc[team_level['treatment'] == 1, 'contract_expiring'] = np.random.binomial(1, 0.7, \n",
    "                                                                                        (team_level['treatment'] == 1).sum())\n",
    "\n",
    "print(\"Instrument correlation with treatment:\")\n",
    "print(pd.crosstab(team_level['contract_expiring'], team_level['treatment'], normalize='index'))\n",
    "\n",
    "# Initialize IV analyzer\n",
    "iv_analyzer = CausalInferenceAnalyzer(\n",
    "    data=team_level,\n",
    "    treatment_col='treatment',\n",
    "    outcome_col='post_win_rate'\n",
    ")\n",
    "\n",
    "# Run instrumental variables estimation\n",
    "iv_result = iv_analyzer.instrumental_variables(\n",
    "    instrument='contract_expiring',\n",
    "    covariates=['pre_win_rate', 'payroll']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì INSTRUMENTAL VARIABLES (2SLS) RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nIV Estimate (LATE): {iv_result['iv_estimate']:+.3f}\")\n",
    "print(f\"Standard Error: {iv_result['std_error']:.4f}\")\n",
    "print(f\"95% Confidence Interval: [{iv_result['ci_lower']:+.3f}, {iv_result['ci_upper']:+.3f}]\")\n",
    "print(f\"P-value: {iv_result['p_value']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä First Stage (Instrument ‚Üí Treatment):\")\n",
    "print(f\"   F-statistic: {iv_result['first_stage_f']:.2f}\")\n",
    "if iv_result['first_stage_f'] > 10:\n",
    "    print(f\"   ‚úì Strong instrument (F > 10)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Weak instrument (F < 10) - IV estimates unreliable\")\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"   Local Average Treatment Effect (LATE):\")\n",
    "print(f\"   For teams induced to change coaches due to contract expiration,\")\n",
    "print(f\"   the effect is {iv_result['iv_estimate']:+.3f} change in win rate\")\n",
    "print(f\"   ({iv_result['iv_estimate']*82:+.1f} wins per season)\")\n",
    "\n",
    "print(f\"\\n‚ö° Performance: {iv_result['execution_time']*1000:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Method 4: Regression Discontinuity Design (RDD)\n",
    "\n",
    "**Scenario:** Teams fire coaches if win rate falls below a threshold (e.g., 40%).\n",
    "\n",
    "**Idea:** Compare teams just above vs. just below the threshold.\n",
    "- Teams at 39% vs. 41% win rate are very similar\n",
    "- But one group gets treatment (coaching change), other doesn't\n",
    "- Acts as a \"natural experiment\"\n",
    "\n",
    "**Key Assumption:** No manipulation of the running variable (win rate)\n",
    "\n",
    "**Advantage:** Very credible if threshold exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"firing threshold\" scenario\n",
    "# Teams below 40% win rate in first half get new coaches\n",
    "team_level['running_var'] = team_level['pre_win_rate']  # This is our running variable\n",
    "cutoff = 0.40\n",
    "\n",
    "# Simulate sharp RDD: Treatment = 1 if below cutoff\n",
    "team_level['rdd_treatment'] = (team_level['running_var'] < cutoff).astype(int)\n",
    "\n",
    "print(f\"Regression Discontinuity Setup:\")\n",
    "print(f\"   Cutoff: {cutoff:.2f} (40% win rate)\")\n",
    "print(f\"   Teams below cutoff: {team_level['rdd_treatment'].sum()}\")\n",
    "print(f\"   Teams above cutoff: {(1-team_level['rdd_treatment']).sum()}\")\n",
    "\n",
    "# Initialize RDD analyzer\n",
    "rdd_analyzer = CausalInferenceAnalyzer(\n",
    "    data=team_level,\n",
    "    treatment_col='rdd_treatment',\n",
    "    outcome_col='post_win_rate'\n",
    ")\n",
    "\n",
    "# Run regression discontinuity\n",
    "rdd_result = rdd_analyzer.regression_discontinuity(\n",
    "    running_var='running_var',\n",
    "    cutoff=cutoff,\n",
    "    bandwidth=0.10  # Only use teams within 10 percentage points of cutoff\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì REGRESSION DISCONTINUITY RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nRDD Estimate (LATE at cutoff): {rdd_result['rdd_estimate']:+.3f}\")\n",
    "print(f\"Standard Error: {rdd_result['std_error']:.4f}\")\n",
    "print(f\"95% Confidence Interval: [{rdd_result['ci_lower']:+.3f}, {rdd_result['ci_upper']:+.3f}]\")\n",
    "print(f\"P-value: {rdd_result['p_value']:.4f}\")\n",
    "\n",
    "print(f\"\\nBandwidth: {rdd_result['bandwidth']:.3f}\")\n",
    "print(f\"Observations in bandwidth: {rdd_result['n_obs']}\")\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"   At the firing threshold ({cutoff:.0%} win rate),\")\n",
    "print(f\"   getting a new coach causes a {rdd_result['rdd_estimate']:+.3f} change\")\n",
    "print(f\"   in subsequent win rate ({rdd_result['rdd_estimate']*82:+.1f} wins per season)\")\n",
    "print(f\"\\n   ‚úì Highly credible if threshold is real and not manipulated\")\n",
    "\n",
    "print(f\"\\n‚ö° Performance: {rdd_result['execution_time']*1000:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize RDD: Discontinuity at Cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Scatter plot: pre-treatment win rate vs. post-treatment win rate\n",
    "below_cutoff = team_level[team_level['running_var'] < cutoff]\n",
    "above_cutoff = team_level[team_level['running_var'] >= cutoff]\n",
    "\n",
    "ax.scatter(below_cutoff['running_var'], below_cutoff['post_win_rate'], \n",
    "          color='red', s=100, alpha=0.6, label='Treatment (New Coach)', marker='o')\n",
    "ax.scatter(above_cutoff['running_var'], above_cutoff['post_win_rate'], \n",
    "          color='blue', s=100, alpha=0.6, label='Control (Same Coach)', marker='s')\n",
    "\n",
    "# Fit lines on each side of cutoff\n",
    "from numpy.polynomial import Polynomial\n",
    "\n",
    "# Below cutoff\n",
    "below_x = below_cutoff['running_var'].values\n",
    "below_y = below_cutoff['post_win_rate'].values\n",
    "if len(below_x) > 2:\n",
    "    p_below = Polynomial.fit(below_x, below_y, deg=1)\n",
    "    x_below = np.linspace(below_x.min(), cutoff, 100)\n",
    "    ax.plot(x_below, p_below(x_below), 'r-', linewidth=3, alpha=0.8)\n",
    "\n",
    "# Above cutoff\n",
    "above_x = above_cutoff['running_var'].values\n",
    "above_y = above_cutoff['post_win_rate'].values\n",
    "if len(above_x) > 2:\n",
    "    p_above = Polynomial.fit(above_x, above_y, deg=1)\n",
    "    x_above = np.linspace(cutoff, above_x.max(), 100)\n",
    "    ax.plot(x_above, p_above(x_above), 'b-', linewidth=3, alpha=0.8)\n",
    "\n",
    "# Mark cutoff and discontinuity\n",
    "ax.axvline(x=cutoff, color='black', linestyle='--', linewidth=2, label='Firing Threshold')\n",
    "\n",
    "# Show jump at cutoff\n",
    "if len(below_x) > 2 and len(above_x) > 2:\n",
    "    y_below_at_cutoff = p_below(cutoff)\n",
    "    y_above_at_cutoff = p_above(cutoff)\n",
    "    jump = y_above_at_cutoff - y_below_at_cutoff\n",
    "    \n",
    "    ax.plot([cutoff, cutoff], [y_below_at_cutoff, y_above_at_cutoff], \n",
    "           'g-', linewidth=4, label=f'RDD Effect = {jump:+.3f}')\n",
    "\n",
    "ax.set_xlabel('Pre-Treatment Win Rate (Running Variable)', fontsize=12)\n",
    "ax.set_ylabel('Post-Treatment Win Rate (Outcome)', fontsize=12)\n",
    "ax.set_title('Regression Discontinuity: Coaching Change Effect at Firing Threshold', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä RDD Visualization:\")\n",
    "print(\"   ‚úì Discontinuity (jump) at cutoff = causal effect\")\n",
    "print(\"   ‚úì If no jump, no effect of coaching change\")\n",
    "print(\"   ‚úì Slope changes = heterogeneous treatment effects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare All Methods\n",
    "\n",
    "**Which method is best?**\n",
    "\n",
    "It depends on:\n",
    "- Your data structure\n",
    "- Available instruments\n",
    "- Plausibility of assumptions\n",
    "- Threat of endogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Method': 'Naive Comparison',\n",
    "        'Estimate': naive_effect,\n",
    "        'Wins/Season': naive_effect * 82,\n",
    "        'P-value': 'N/A',\n",
    "        'Bias': '‚ùå High',\n",
    "        'Assumptions': 'None (wrong)'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'PSM',\n",
    "        'Estimate': psm_result['ate'],\n",
    "        'Wins/Season': psm_result['ate'] * 82,\n",
    "        'P-value': f\"{psm_result['p_value']:.4f}\",\n",
    "        'Bias': '‚úì Low',\n",
    "        'Assumptions': 'Selection on observables'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'DiD',\n",
    "        'Estimate': did_result['did_estimate'],\n",
    "        'Wins/Season': did_result['did_estimate'] * 82,\n",
    "        'P-value': f\"{did_result['p_value']:.4f}\",\n",
    "        'Bias': '‚úì Low',\n",
    "        'Assumptions': 'Parallel trends'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'IV (2SLS)',\n",
    "        'Estimate': iv_result['iv_estimate'],\n",
    "        'Wins/Season': iv_result['iv_estimate'] * 82,\n",
    "        'P-value': f\"{iv_result['p_value']:.4f}\",\n",
    "        'Bias': '‚úì Low',\n",
    "        'Assumptions': 'Valid instrument'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'RDD',\n",
    "        'Estimate': rdd_result['rdd_estimate'],\n",
    "        'Wins/Season': rdd_result['rdd_estimate'] * 82,\n",
    "        'P-value': f\"{rdd_result['p_value']:.4f}\",\n",
    "        'Bias': '‚úì‚úì Very Low',\n",
    "        'Assumptions': 'No manipulation at cutoff'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"CAUSAL INFERENCE METHOD COMPARISON\")\n",
    "print(\"=\"*90)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"üìä KEY INSIGHTS\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£  NAIVE COMPARISON (‚ùå DON'T USE):\")\n",
    "print(\"   Confounded by regression to mean, selection bias, time trends\")\n",
    "print(f\"   Overestimates effect: {naive_effect:+.3f} vs true ~0.05\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£  PSM (‚úì Good for Cross-Sectional Data):\")\n",
    "print(\"   Controls for selection on observables\")\n",
    "print(\"   Assumes: No unobserved confounders\")\n",
    "print(\"   Best for: Post-treatment comparisons with rich covariates\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£  DiD (‚úì‚úì Gold Standard for Panel Data):\")\n",
    "print(\"   Controls for time-invariant confounders + time trends\")\n",
    "print(\"   Assumes: Parallel trends (testable!)\")\n",
    "print(\"   Best for: Before/after with control group\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£  IV (‚úì Handles Endogeneity):\")\n",
    "print(\"   Corrects for unobserved confounders\")\n",
    "print(\"   Assumes: Valid instrument exists (hard to find!)\")\n",
    "print(\"   Best for: When treatment is endogenous\")\n",
    "print(f\"   Check: First-stage F = {iv_result['first_stage_f']:.1f} (need >10)\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£  RDD (‚úì‚úì‚úì Most Credible if Threshold Exists):\")\n",
    "print(\"   Uses discontinuity as natural experiment\")\n",
    "print(\"   Assumes: No manipulation of running variable\")\n",
    "print(\"   Best for: Clear cutoff rules (contracts, performance thresholds)\")\n",
    "print(\"   Limitation: Only estimates effect AT the cutoff (LATE)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"üéØ RECOMMENDATION\")\n",
    "print(\"=\"*90)\n",
    "print(\"Use MULTIPLE methods as robustness checks:\")\n",
    "print(\"  ‚Ä¢ If estimates agree ‚Üí Confident in causal effect\")\n",
    "print(\"  ‚Ä¢ If estimates differ ‚Üí Investigate why (violations of assumptions?)\")\n",
    "print(\"  ‚Ä¢ Always prefer DiD or RDD when applicable\")\n",
    "print(\"  ‚Ä¢ Report all methods for transparency\")\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Business Recommendations\n",
    "\n",
    "**Question:** Should we fire our coach if the team is struggling?\n",
    "\n",
    "**Analysis Summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXECUTIVE SUMMARY: COACHING CHANGE IMPACT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "avg_causal_effect = np.mean([psm_result['ate'], did_result['did_estimate'], \n",
    "                             iv_result['iv_estimate'], rdd_result['rdd_estimate']])\n",
    "avg_wins = avg_causal_effect * 82\n",
    "\n",
    "print(f\"\\nüìä CAUSAL EFFECT ESTIMATE:\")\n",
    "print(f\"   Average across 4 methods: {avg_causal_effect:+.3f} change in win rate\")\n",
    "print(f\"   Translates to: {avg_wins:+.1f} wins per 82-game season\")\n",
    "\n",
    "if avg_causal_effect > 0.03:\n",
    "    print(f\"\\n‚úÖ RECOMMENDATION: COACHING CHANGES ARE EFFECTIVE\")\n",
    "    print(f\"   ‚Ä¢ Hiring a new coach improves performance by ~{avg_wins:.0f} wins/season\")\n",
    "    print(f\"   ‚Ä¢ Cost-benefit: If coach salary < value of {avg_wins:.0f} wins, do it!\")\n",
    "    print(f\"   ‚Ä¢ Effect is statistically significant across multiple methods\")\n",
    "elif avg_causal_effect < -0.03:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: COACHING CHANGES MAY HURT PERFORMANCE\")\n",
    "    print(f\"   ‚Ä¢ Teams lose ~{abs(avg_wins):.0f} wins after coaching changes\")\n",
    "    print(f\"   ‚Ä¢ Possible reasons: Disruption, learning curve, wrong hires\")\n",
    "    print(f\"   ‚Ä¢ RECOMMENDATION: Avoid mid-season changes unless absolutely necessary\")\n",
    "else:\n",
    "    print(f\"\\n‚öñÔ∏è  FINDING: COACHING CHANGES HAVE MINIMAL EFFECT\")\n",
    "    print(f\"   ‚Ä¢ Effect is small and possibly not statistically significant\")\n",
    "    print(f\"   ‚Ä¢ Much of the 'improvement' after coach firings is regression to mean\")\n",
    "    print(f\"   ‚Ä¢ RECOMMENDATION: Focus on player development and roster changes instead\")\n",
    "\n",
    "print(f\"\\nüéØ KEY TAKEAWAYS:\")\n",
    "print(f\"   1. Naive comparisons OVERESTIMATE coaching effects\")\n",
    "print(f\"   2. Must control for: selection bias, time trends, regression to mean\")\n",
    "print(f\"   3. Use multiple causal inference methods for robust conclusions\")\n",
    "print(f\"   4. Check assumptions (parallel trends, instrument validity, etc.)\")\n",
    "\n",
    "print(f\"\\nüíº BUSINESS IMPLICATIONS:\")\n",
    "if avg_wins > 5:\n",
    "    print(f\"   ‚Ä¢ Strong case for coaching change if underperforming\")\n",
    "    print(f\"   ‚Ä¢ {avg_wins:.0f} extra wins could mean playoffs (~$10-20M revenue)\")\n",
    "    print(f\"   ‚Ä¢ Invest in thorough coach search process\")\n",
    "elif avg_wins > 2:\n",
    "    print(f\"   ‚Ä¢ Moderate benefit from coaching changes\")\n",
    "    print(f\"   ‚Ä¢ Worth doing if coach relationship is broken\")\n",
    "    print(f\"   ‚Ä¢ But don't expect miracles - roster quality still dominates\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Minimal or no benefit from coaching changes\")\n",
    "    print(f\"   ‚Ä¢ Better to invest in player development, scouting, analytics\")\n",
    "    print(f\"   ‚Ä¢ Only change coach if culture/relationship issues exist\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì Causal inference reveals the TRUE effect, beyond naive correlation\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary: When to Use Each Method\n",
    "\n",
    "| Method | Best Use Case | Key Assumption | Difficulty |\n",
    "|--------|--------------|----------------|------------|\n",
    "| **PSM** | Cross-sectional comparison | No unobserved confounders | ‚≠ê‚≠ê Easy |\n",
    "| **DiD** | Panel data with treatment timing | Parallel trends | ‚≠ê‚≠ê Easy |\n",
    "| **IV** | Endogenous treatment | Valid instrument | ‚≠ê‚≠ê‚≠ê‚≠ê Hard |\n",
    "| **RDD** | Sharp cutoff rule exists | No manipulation at cutoff | ‚≠ê‚≠ê‚≠ê Medium |\n",
    "\n",
    "### Performance\n",
    "All methods run in **<500ms** - suitable for interactive analysis.\n",
    "\n",
    "### Next Steps\n",
    "- Try survival analysis for career longevity (`notebooks/05_survival_analysis.ipynb`)\n",
    "- Explore ensemble forecasting for playoff predictions\n",
    "- See `docs/QUICK_REFERENCE.md` for all available methods\n",
    "\n",
    "---\n",
    "\n",
    "**Key Lesson:** Always think causally! Correlation is not causation. Use proper causal inference methods to make better decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
